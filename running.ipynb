{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job with args:\n",
      "['run_experiments.py', '30', '25', '2', '1', 'True']\n",
      "Loaded data shapes:\n",
      "(10800, 80, 64) (10800, 1)\n",
      "Using CPU\n",
      "X shape: (10800, 80, 64, 1)\n",
      "y shape: (10800, 2)\n",
      "New model name: ./model/EEGNet_fusion_Executed_103sub_0.h5\n",
      "Model EEGNet_fusion_Executed_103sub total training time was 1690.6588184833527 seconds\n",
      "That is 0.22363211884700432 seconds per sample\n",
      "Train shape: (7560, 80, 64, 1). Test shape: (2160, 80, 64, 1)\n",
      "Classification accuracy for ./model/EEGNet_fusion_Executed_103sub_0.h5 : 0.943056 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\bci\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\bci\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "2024-12-14 02:58:37.682641: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
      "Traceback (most recent call last):\n",
      "  File \"run_experiments.py\", line 93, in <module>\n",
      "    experiments.append(run_experiment(X, y, experiment_103sub))\n",
      "  File \"d:\\CodesNStuffs\\NeuralScience\\BCI_mini_project\\EEGMotorImagery\\training_testing.py\", line 131, in run_experiment\n",
      "    multi_branch, experiment.get_epochs(), test_model=test_model)\n",
      "  File \"d:\\CodesNStuffs\\NeuralScience\\BCI_mini_project\\EEGMotorImagery\\training_testing.py\", line 68, in train_test_model\n",
      "    acc, equals, preds = predict_accuracy(model, X_test, y_test, new_model_name, multi_branch=multi_branch)\n",
      "ValueError: not enough values to unpack (expected 3, got 2)\n"
     ]
    }
   ],
   "source": [
    "! python run_experiments.py 30 25 2 1 True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\bci\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\bci\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\bci\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\bci\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\bci\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 80, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 80, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 80, 64, 8)    512         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 80, 64, 16)   1536        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 80, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 80, 64, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 80, 64, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 80, 64, 32)   4096        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseConv (None, 80, 1, 16)    1024        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_1 (DepthwiseCo (None, 80, 1, 32)    2048        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 80, 64, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 80, 1, 16)    64          depthwise_conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 80, 1, 32)    128         depthwise_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_2 (DepthwiseCo (None, 80, 1, 64)    4096        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 80, 1, 16)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 80, 1, 32)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 80, 1, 64)    256         depthwise_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 20, 1, 16)    0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 20, 1, 32)    0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 80, 1, 64)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 20, 1, 16)    0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 20, 1, 32)    0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 20, 1, 64)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d (SeparableConv (None, 20, 1, 16)    384         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 20, 1, 32)    1536        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 20, 1, 64)    0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 20, 1, 16)    64          separable_conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 20, 1, 32)    128         separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 20, 1, 64)    6144        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 20, 1, 16)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 20, 1, 32)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 20, 1, 64)    256         separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 2, 1, 16)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 1, 32)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 20, 1, 64)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2, 1, 16)     0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 2, 1, 32)     0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 2, 1, 64)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32)           0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2, 1, 64)     0           average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 96)           0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 128)          0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 224)          0           concatenate[0][0]                \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 224)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            450         flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 2)            0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 22,946\n",
      "Trainable params: 22,386\n",
      "Non-trainable params: 560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Step 1: Load the trained model\n",
    "model_path = './model/EEGNet_fusion_Executed_103sub_0.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Optional: Print model summary to ensure it's loaded correctly\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data shapes:\n",
      "(17640, 64, 80) (17640, 1)\n"
     ]
    }
   ],
   "source": [
    "from data_loader import load_data\n",
    "from run_type import RunType\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Step 2: Load and preprocess the test data\n",
    "nr_of_subj = 50  # Number of subjects to test\n",
    "trial_type = RunType.Executed  # Or RunType.Imagined based on your data\n",
    "use_cpu = False  # Use CPU or GPU depending on your setup\n",
    "\n",
    "# Load test data (with preprocessing)\n",
    "X_test, y_test = load_data(nr_of_subj=nr_of_subj, trial_type=trial_type, chunk_data=True, chunks=8,\n",
    "                           cpu_format=use_cpu, preprocessing=True, hp_freq=0.5, bp_low=2, bp_high=60, notch=True,\n",
    "                           hp_filter=False, bp_filter=True, artifact_removal=True)\n",
    "\n",
    "# Format the labels to categorical\n",
    "y_test = to_categorical(y_test, num_classes=2)  # Update num_classes as per your case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Reshape data for the model (add channel dimension)\n",
    "# The model expects input of shape (80, 64, 1) but your data is in (64, 80, 1)\n",
    "# So we need to transpose the data dimensions\n",
    "\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)  # Shape: (samples, height, width, 1)\n",
    "\n",
    "# Transpose data from (64, 80, 1) to (80, 64, 1)\n",
    "X_test_reshaped = X_test_reshaped.transpose(0, 2, 1, 3)  # Transpose the last two dimensions\n",
    "\n",
    "# Prepare the data as 3 copies (multi-branch input)\n",
    "X_test_input = [X_test_reshaped, X_test_reshaped, X_test_reshaped]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Make predictions using the trained model\n",
    "predictions = model.predict(X_test_input)\n",
    "\n",
    "# Convert predictions to class labels (0 or 1)\n",
    "predicted_classes = predictions.argmax(axis=-1)\n",
    "\n",
    "# Convert the ground truth labels from one-hot encoding to integers\n",
    "y_test_classes = y_test.argmax(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 50.41%\n",
      "Confusion Matrix:\n",
      " [[4767 4105]\n",
      " [4643 4125]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Step 5: Evaluate the model's performance\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_classes, predicted_classes)\n",
    "print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_classes, predicted_classes)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = {\n",
    "    'True Labels': y_test_classes,\n",
    "    'Predicted Labels': predicted_classes\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = 'predicted_vs_true_labels.csv'\n",
    "df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
